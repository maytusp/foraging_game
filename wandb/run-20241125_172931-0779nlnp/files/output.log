train_single_dqn.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)
  image_seq_input = torch.tensor(image_seq, dtype=torch.float32).unsqueeze(0).to(device)
Episode 1/100000, Total Reward: 0, loss: None
Episode 2/100000, Total Reward: 0, loss: None
Episode 3/100000, Total Reward: 0, loss: None
Episode 4/100000, Total Reward: 0, loss: None
Episode 5/100000, Total Reward: 0, loss: None
Episode 6/100000, Total Reward: 0, loss: None
Episode 7/100000, Total Reward: 0, loss: None
Episode 8/100000, Total Reward: 0, loss: None
Episode 9/100000, Total Reward: 0, loss: None
Episode 10/100000, Total Reward: 0, loss: None
Episode 11/100000, Total Reward: 0, loss: None
Episode 12/100000, Total Reward: 0, loss: None
Episode 13/100000, Total Reward: 0, loss: None
Episode 14/100000, Total Reward: 0, loss: None
Episode 15/100000, Total Reward: 0, loss: None
Episode 16/100000, Total Reward: 0, loss: None
Episode 17/100000, Total Reward: 0, loss: None
Episode 18/100000, Total Reward: 0, loss: None
Episode 19/100000, Total Reward: 0, loss: None
Episode 20/100000, Total Reward: 0, loss: None
Episode 21/100000, Total Reward: 0, loss: None
Episode 22/100000, Total Reward: 0, loss: None
Episode 23/100000, Total Reward: 0, loss: None
Episode 24/100000, Total Reward: 0, loss: None
Episode 25/100000, Total Reward: 0, loss: None
Episode 26/100000, Total Reward: 0, loss: None
Episode 27/100000, Total Reward: 0, loss: None
Episode 28/100000, Total Reward: 0, loss: None
Episode 29/100000, Total Reward: 0, loss: None
Episode 30/100000, Total Reward: 0, loss: None
Episode 31/100000, Total Reward: 0, loss: None
Episode 32/100000, Total Reward: 0, loss: None
Episode 33/100000, Total Reward: 0, loss: None
Episode 34/100000, Total Reward: 0, loss: None
Episode 35/100000, Total Reward: 0, loss: None
Episode 36/100000, Total Reward: 0, loss: None
Episode 37/100000, Total Reward: 0, loss: None
Episode 38/100000, Total Reward: 0, loss: None
Episode 39/100000, Total Reward: 0, loss: None
Episode 40/100000, Total Reward: 0, loss: None
Episode 41/100000, Total Reward: 0, loss: None
Episode 42/100000, Total Reward: 0, loss: None
Episode 43/100000, Total Reward: 0, loss: None
Episode 44/100000, Total Reward: 0, loss: None
Episode 45/100000, Total Reward: 0, loss: None
Episode 46/100000, Total Reward: 0, loss: None
Episode 47/100000, Total Reward: 0, loss: None
Episode 48/100000, Total Reward: 0, loss: None
Episode 49/100000, Total Reward: 0, loss: None
Episode 50/100000, Total Reward: 0, loss: None
Episode 51/100000, Total Reward: 0, loss: None
Episode 52/100000, Total Reward: 0, loss: None
Episode 53/100000, Total Reward: 0, loss: None
Episode 54/100000, Total Reward: 0, loss: None
Episode 55/100000, Total Reward: 0, loss: None
Episode 56/100000, Total Reward: 0, loss: None
Episode 57/100000, Total Reward: 0, loss: None
Episode 58/100000, Total Reward: 0, loss: None
Episode 59/100000, Total Reward: 0, loss: None
Episode 60/100000, Total Reward: 0, loss: None
Episode 61/100000, Total Reward: 0, loss: None
Episode 62/100000, Total Reward: 0, loss: None
Episode 63/100000, Total Reward: 0, loss: None
Episode 64/100000, Total Reward: 0, loss: None
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
/Users/user/anaconda3/envs/robot/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64, 64])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 65/100000, Total Reward: 5, loss: 10.176763534545898
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 66/100000, Total Reward: -5, loss: 14.871550559997559
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 67/100000, Total Reward: -5, loss: 15.235186576843262
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 68/100000, Total Reward: -5, loss: 14.454024314880371
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 69/100000, Total Reward: 5, loss: 12.10937786102295
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 70/100000, Total Reward: -5, loss: 14.453728675842285
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 71/100000, Total Reward: -5, loss: 10.156253814697266
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 72/100000, Total Reward: -5, loss: 16.406518936157227
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 73/100000, Total Reward: -5, loss: 12.890900611877441
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 74/100000, Total Reward: -5, loss: 12.890625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 75/100000, Total Reward: -5, loss: 14.84375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 76/100000, Total Reward: -5, loss: 13.671875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 77/100000, Total Reward: -5, loss: 13.28125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 78/100000, Total Reward: -5, loss: 12.5
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 79/100000, Total Reward: -5, loss: 11.71875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 80/100000, Total Reward: -5, loss: 12.890625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 81/100000, Total Reward: -5, loss: 15.234375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 82/100000, Total Reward: -5, loss: 13.28125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 83/100000, Total Reward: -5, loss: 14.453125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 84/100000, Total Reward: -5, loss: 9.765625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 85/100000, Total Reward: -5, loss: 15.234375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 86/100000, Total Reward: -5, loss: 15.625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 87/100000, Total Reward: -5, loss: 14.453125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 88/100000, Total Reward: -5, loss: 11.71875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 89/100000, Total Reward: -5, loss: 12.109375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 90/100000, Total Reward: -5, loss: 17.578125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 91/100000, Total Reward: 5, loss: 14.453125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 92/100000, Total Reward: -5, loss: 13.671875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 93/100000, Total Reward: -5, loss: 15.234375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 94/100000, Total Reward: -5, loss: 14.84375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 95/100000, Total Reward: -5, loss: 15.625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 96/100000, Total Reward: -5, loss: 16.40625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 97/100000, Total Reward: -5, loss: 15.234375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 98/100000, Total Reward: -5, loss: 16.796875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 99/100000, Total Reward: -5, loss: 14.0625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 100/100000, Total Reward: -5, loss: 13.671875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 101/100000, Total Reward: -5, loss: 15.625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 102/100000, Total Reward: -5, loss: 12.890625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 103/100000, Total Reward: -5, loss: 13.671875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 104/100000, Total Reward: -5, loss: 11.71875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 105/100000, Total Reward: -5, loss: 14.84375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 106/100000, Total Reward: -5, loss: 13.671875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 107/100000, Total Reward: -5, loss: 13.28125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 108/100000, Total Reward: -5, loss: 12.109375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 109/100000, Total Reward: -5, loss: 14.0625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 110/100000, Total Reward: -5, loss: 15.625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 111/100000, Total Reward: -5, loss: 15.625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 112/100000, Total Reward: -5, loss: 16.796875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 113/100000, Total Reward: -5, loss: 17.96875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 114/100000, Total Reward: -5, loss: 15.234375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 115/100000, Total Reward: -5, loss: 13.671875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 116/100000, Total Reward: -5, loss: 12.5
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 117/100000, Total Reward: -5, loss: 13.28125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 118/100000, Total Reward: -5, loss: 14.84375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 119/100000, Total Reward: -5, loss: 17.1875
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 120/100000, Total Reward: -5, loss: 18.75
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 121/100000, Total Reward: -5, loss: 16.015625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 122/100000, Total Reward: -5, loss: 12.890625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 123/100000, Total Reward: -5, loss: 14.453125
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 124/100000, Total Reward: -5, loss: 14.84375
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Episode 125/100000, Total Reward: -5, loss: 16.015625
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
rewards torch.Size([64, 1])
q_targets torch.Size([64, 64])
q_values torch.Size([64])
Traceback (most recent call last):
  File "train_single_dqn.py", line 373, in <module>
    train_drqn(env, 100000)
  File "train_single_dqn.py", line 266, in train_drqn
    loss = agent.train()
  File "train_single_dqn.py", line 204, in train
    loss.backward()
  File "/Users/user/anaconda3/envs/robot/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/Users/user/anaconda3/envs/robot/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/Users/user/anaconda3/envs/robot/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
